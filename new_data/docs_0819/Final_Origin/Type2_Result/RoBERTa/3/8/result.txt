RoBERTa
Pretrained Model=hfl/chinese-roberta-wwm-ext

=====================================
epoch=10
batch_size=8
lr=2e-05

=====================================
Epochs: 1
            | Train Loss:  0.076
            | Train Accuracy:  0.882
            | Val Loss:  0.066
            | Val Accuracy:  0.920
=====================================
total_acc_val / len(val_dataset) = 91.98, best_dev_acc = 91.98
Epochs: 2
            | Train Loss:  0.053
            | Train Accuracy:  0.914
            | Val Loss:  0.091
            | Val Accuracy:  0.942
=====================================
total_acc_val / len(val_dataset) = 94.18, best_dev_acc = 94.18
Epochs: 3
            | Train Loss:  0.041
            | Train Accuracy:  0.931
            | Val Loss:  0.074
            | Val Accuracy:  0.904
=====================================
total_acc_val / len(val_dataset) = 90.41, best_dev_acc = 94.18
Epochs: 4
            | Train Loss:  0.028
            | Train Accuracy:  0.946
            | Val Loss:  0.095
            | Val Accuracy:  0.926
=====================================
total_acc_val / len(val_dataset) = 92.61, best_dev_acc = 94.18
Epochs: 5
            | Train Loss:  0.017
            | Train Accuracy:  0.960
            | Val Loss:  0.082
            | Val Accuracy:  0.936
=====================================
total_acc_val / len(val_dataset) = 93.55, best_dev_acc = 94.18
Epochs: 6
            | Train Loss:  0.016
            | Train Accuracy:  0.972
            | Val Loss:  0.134
            | Val Accuracy:  0.931
=====================================
total_acc_val / len(val_dataset) = 93.08, best_dev_acc = 94.18
Epochs: 7
            | Train Loss:  0.010
            | Train Accuracy:  0.978
            | Val Loss:  0.147
            | Val Accuracy:  0.937
=====================================
total_acc_val / len(val_dataset) = 93.71, best_dev_acc = 94.18
Epochs: 8
            | Train Loss:  0.009
            | Train Accuracy:  0.981
            | Val Loss:  0.116
            | Val Accuracy:  0.940
=====================================
total_acc_val / len(val_dataset) = 94.03, best_dev_acc = 94.18
Epochs: 9
            | Train Loss:  0.006
            | Train Accuracy:  0.988
            | Val Loss:  0.133
            | Val Accuracy:  0.943
=====================================
total_acc_val / len(val_dataset) = 94.34, best_dev_acc = 94.34
Epochs: 10
            | Train Loss:  0.007
            | Train Accuracy:  0.984
            | Val Loss:  0.149
            | Val Accuracy:  0.939
=====================================
total_acc_val / len(val_dataset) = 93.87, best_dev_acc = 94.34
=====================================
Total time:0:41:46.601773
Best Epoch:9
=====================================
scikit-learn Accuracy:94.34
scikit-learn Precision:93.36
scikit-learn Recall Score:94.34
scikit-learn F1 Score:93.78
