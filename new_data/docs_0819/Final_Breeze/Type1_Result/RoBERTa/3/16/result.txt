RoBERTa
Pretrained Model=hfl/chinese-roberta-wwm-ext

=====================================
epoch=10
batch_size=16
lr=2e-05

=====================================
Epochs: 1
            | Train Loss:  0.019
            | Train Accuracy:  0.886
            | Val Loss:  0.017
            | Val Accuracy:  0.909
=====================================
total_acc_val / len(val_dataset) = 90.90, best_dev_acc = 90.90
Epochs: 2
            | Train Loss:  0.006
            | Train Accuracy:  0.969
            | Val Loss:  0.022
            | Val Accuracy:  0.898
=====================================
total_acc_val / len(val_dataset) = 89.76, best_dev_acc = 90.90
Epochs: 3
            | Train Loss:  0.004
            | Train Accuracy:  0.981
            | Val Loss:  0.022
            | Val Accuracy:  0.902
=====================================
total_acc_val / len(val_dataset) = 90.18, best_dev_acc = 90.90
Epochs: 4
            | Train Loss:  0.002
            | Train Accuracy:  0.989
            | Val Loss:  0.028
            | Val Accuracy:  0.906
=====================================
total_acc_val / len(val_dataset) = 90.61, best_dev_acc = 90.90
Epochs: 5
            | Train Loss:  0.002
            | Train Accuracy:  0.991
            | Val Loss:  0.025
            | Val Accuracy:  0.903
=====================================
total_acc_val / len(val_dataset) = 90.33, best_dev_acc = 90.90
Epochs: 6
            | Train Loss:  0.001
            | Train Accuracy:  0.993
            | Val Loss:  0.035
            | Val Accuracy:  0.871
=====================================
total_acc_val / len(val_dataset) = 87.06, best_dev_acc = 90.90
Epochs: 7
            | Train Loss:  0.001
            | Train Accuracy:  0.995
            | Val Loss:  0.038
            | Val Accuracy:  0.878
=====================================
total_acc_val / len(val_dataset) = 87.77, best_dev_acc = 90.90
Epochs: 8
            | Train Loss:  0.001
            | Train Accuracy:  0.993
            | Val Loss:  0.033
            | Val Accuracy:  0.898
=====================================
total_acc_val / len(val_dataset) = 89.76, best_dev_acc = 90.90
Epochs: 9
            | Train Loss:  0.001
            | Train Accuracy:  0.996
            | Val Loss:  0.031
            | Val Accuracy:  0.910
=====================================
total_acc_val / len(val_dataset) = 91.04, best_dev_acc = 91.04
Epochs: 10
            | Train Loss:  0.001
            | Train Accuracy:  0.996
            | Val Loss:  0.031
            | Val Accuracy:  0.910
=====================================
total_acc_val / len(val_dataset) = 91.04, best_dev_acc = 91.04
=====================================
Total time:1:51:04.899333
Best Epoch:9
=====================================
scikit-learn Accuracy:92.19
scikit-learn Precision:91.64
scikit-learn Recall Score:92.19
scikit-learn F1 Score:91.82
