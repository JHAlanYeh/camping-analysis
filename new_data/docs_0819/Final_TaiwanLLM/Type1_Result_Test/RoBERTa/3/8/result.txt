RoBERTa
Pretrained Model=hfl/chinese-roberta-wwm-ext

=====================================
epoch=10
batch_size=8
lr=2e-05

=====================================
Epochs: 1
            | Train Loss:  0.047
            | Train Accuracy:  0.851
            | Val Loss:  0.027
            | Val Accuracy:  0.925
=====================================
total_acc_val / len(val_dataset) = 92.46, best_dev_acc = 92.46
Epochs: 2
            | Train Loss:  0.014
            | Train Accuracy:  0.964
            | Val Loss:  0.049
            | Val Accuracy:  0.872
=====================================
total_acc_val / len(val_dataset) = 87.20, best_dev_acc = 92.46
Epochs: 3
            | Train Loss:  0.007
            | Train Accuracy:  0.981
            | Val Loss:  0.071
            | Val Accuracy:  0.849
=====================================
total_acc_val / len(val_dataset) = 84.92, best_dev_acc = 92.46
Epochs: 4
            | Train Loss:  0.005
            | Train Accuracy:  0.986
            | Val Loss:  0.041
            | Val Accuracy:  0.916
=====================================
total_acc_val / len(val_dataset) = 91.61, best_dev_acc = 92.46
Epochs: 5
            | Train Loss:  0.004
            | Train Accuracy:  0.989
            | Val Loss:  0.052
            | Val Accuracy:  0.898
=====================================
total_acc_val / len(val_dataset) = 89.76, best_dev_acc = 92.46
Epochs: 6
            | Train Loss:  0.004
            | Train Accuracy:  0.990
            | Val Loss:  0.061
            | Val Accuracy:  0.893
=====================================
total_acc_val / len(val_dataset) = 89.33, best_dev_acc = 92.46
Epochs: 7
            | Train Loss:  0.003
            | Train Accuracy:  0.991
            | Val Loss:  0.042
            | Val Accuracy:  0.930
=====================================
total_acc_val / len(val_dataset) = 93.03, best_dev_acc = 93.03
Epochs: 8
            | Train Loss:  0.003
            | Train Accuracy:  0.993
            | Val Loss:  0.044
            | Val Accuracy:  0.920
=====================================
total_acc_val / len(val_dataset) = 92.03, best_dev_acc = 93.03
Epochs: 9
            | Train Loss:  0.003
            | Train Accuracy:  0.992
            | Val Loss:  0.079
            | Val Accuracy:  0.871
=====================================
total_acc_val / len(val_dataset) = 87.06, best_dev_acc = 93.03
Epochs: 10
            | Train Loss:  0.002
            | Train Accuracy:  0.995
            | Val Loss:  0.070
            | Val Accuracy:  0.871
=====================================
total_acc_val / len(val_dataset) = 87.06, best_dev_acc = 93.03
=====================================
Total time:1:56:54.380594
Best Epoch:7
=====================================
scikit-learn Accuracy:92.61
scikit-learn Precision:94.17
scikit-learn Recall Score:92.61
scikit-learn F1 Score:93.10
