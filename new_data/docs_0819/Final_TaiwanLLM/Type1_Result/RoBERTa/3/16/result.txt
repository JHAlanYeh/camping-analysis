RoBERTa
Pretrained Model=hfl/chinese-roberta-wwm-ext

=====================================
epoch=10
batch_size=16
lr=2e-05

=====================================
Epochs: 1
            | Train Loss:  0.024
            | Train Accuracy:  0.849
            | Val Loss:  0.012
            | Val Accuracy:  0.932
=====================================
total_acc_val / len(val_dataset) = 93.17, best_dev_acc = 93.17
Epochs: 2
            | Train Loss:  0.007
            | Train Accuracy:  0.964
            | Val Loss:  0.021
            | Val Accuracy:  0.910
=====================================
total_acc_val / len(val_dataset) = 91.04, best_dev_acc = 93.17
Epochs: 3
            | Train Loss:  0.004
            | Train Accuracy:  0.981
            | Val Loss:  0.034
            | Val Accuracy:  0.852
=====================================
total_acc_val / len(val_dataset) = 85.21, best_dev_acc = 93.17
Epochs: 4
            | Train Loss:  0.002
            | Train Accuracy:  0.986
            | Val Loss:  0.020
            | Val Accuracy:  0.926
=====================================
total_acc_val / len(val_dataset) = 92.60, best_dev_acc = 93.17
Epochs: 5
            | Train Loss:  0.002
            | Train Accuracy:  0.990
            | Val Loss:  0.026
            | Val Accuracy:  0.925
=====================================
total_acc_val / len(val_dataset) = 92.46, best_dev_acc = 93.17
Epochs: 6
            | Train Loss:  0.002
            | Train Accuracy:  0.991
            | Val Loss:  0.021
            | Val Accuracy:  0.913
=====================================
total_acc_val / len(val_dataset) = 91.32, best_dev_acc = 93.17
Epochs: 7
            | Train Loss:  0.001
            | Train Accuracy:  0.994
            | Val Loss:  0.023
            | Val Accuracy:  0.932
=====================================
total_acc_val / len(val_dataset) = 93.17, best_dev_acc = 93.17
Epochs: 8
            | Train Loss:  0.001
            | Train Accuracy:  0.992
            | Val Loss:  0.016
            | Val Accuracy:  0.946
=====================================
total_acc_val / len(val_dataset) = 94.59, best_dev_acc = 94.59
Epochs: 9
            | Train Loss:  0.001
            | Train Accuracy:  0.995
            | Val Loss:  0.027
            | Val Accuracy:  0.909
=====================================
total_acc_val / len(val_dataset) = 90.90, best_dev_acc = 94.59
Epochs: 10
            | Train Loss:  0.001
            | Train Accuracy:  0.993
            | Val Loss:  0.023
            | Val Accuracy:  0.919
=====================================
total_acc_val / len(val_dataset) = 91.89, best_dev_acc = 94.59
=====================================
Total time:1:50:50.362174
Best Epoch:8
=====================================
scikit-learn Accuracy:93.75
scikit-learn Precision:94.13
scikit-learn Recall Score:93.75
scikit-learn F1 Score:93.86
