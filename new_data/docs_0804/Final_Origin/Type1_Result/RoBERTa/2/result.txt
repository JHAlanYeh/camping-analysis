RoBERTa
=====================================
epoch=3
batch_size=16
lr=2e-05

=====================================
Epochs: 1
            | Train Loss:  0.020
            | Train Accuracy:  0.869
            | Val Loss:  0.020
            | Val Accuracy:  0.903
=====================================
total_acc_val / len(dev_dataset) = 90.29, best_dev_acc = 0.00
Epochs: 2
            | Train Loss:  0.011
            | Train Accuracy:  0.929
            | Val Loss:  0.023
            | Val Accuracy:  0.896
=====================================
total_acc_val / len(dev_dataset) = 89.56, best_dev_acc = 90.29
Epochs: 3
            | Train Loss:  0.007
            | Train Accuracy:  0.960
            | Val Loss:  0.023
            | Val Accuracy:  0.904
=====================================
total_acc_val / len(dev_dataset) = 90.44, best_dev_acc = 90.29
=====================================
Total time:0:12:12.028402
Best Epoch:3
=====================================
scikit-learn Accuracy:83.82
scikit-learn Precision:84.73
scikit-learn Recall Score:83.82
scikit-learn F1 Score:84.16
